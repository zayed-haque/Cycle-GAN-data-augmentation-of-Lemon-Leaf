{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0747a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T18:19:50.912319Z",
     "iopub.status.busy": "2023-02-05T18:19:50.911002Z",
     "iopub.status.idle": "2023-02-05T18:19:58.046554Z",
     "shell.execute_reply": "2023-02-05T18:19:58.045699Z",
     "shell.execute_reply.started": "2023-02-05T18:05:26.088366Z"
    },
    "papermill": {
     "duration": 7.144615,
     "end_time": "2023-02-05T18:19:58.046701",
     "exception": false,
     "start_time": "2023-02-05T18:19:50.902086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 18:19:52.509638: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2023-02-05 18:19:52.509847: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os,random,json,PIL,shutil,re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,losses,optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6cbe8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T18:19:58.078259Z",
     "iopub.status.busy": "2023-02-05T18:19:58.069569Z",
     "iopub.status.idle": "2023-02-05T18:20:03.302720Z",
     "shell.execute_reply": "2023-02-05T18:20:03.302152Z",
     "shell.execute_reply.started": "2023-02-05T18:04:02.310737Z"
    },
    "papermill": {
     "duration": 5.250742,
     "end_time": "2023-02-05T18:20:03.302847",
     "exception": false,
     "start_time": "2023-02-05T18:19:58.052105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU: grpc://10.0.0.2:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 18:19:58.065102: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-05 18:19:58.068025: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2023-02-05 18:19:58.068068: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-05 18:19:58.068090: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c611cd6f7326): /proc/driver/nvidia/version does not exist\n",
      "2023-02-05 18:19:58.071338: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 18:19:58.072800: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-05 18:19:58.078611: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-05 18:19:58.103260: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2023-02-05 18:19:58.103319: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2023-02-05 18:19:58.127460: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2023-02-05 18:19:58.127518: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2023-02-05 18:19:58.129042: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS: 8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu=tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('TPU:',tpu.master())\n",
    "except ValueError:\n",
    "    tpu=None\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy= tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print('REPLICAS:',REPLICAS)\n",
    "AUTO=tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa7621c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T18:20:03.319569Z",
     "iopub.status.busy": "2023-02-05T18:20:03.318848Z",
     "iopub.status.idle": "2023-02-05T18:20:03.321246Z",
     "shell.execute_reply": "2023-02-05T18:20:03.320767Z",
     "shell.execute_reply.started": "2023-02-05T18:04:45.649932Z"
    },
    "papermill": {
     "duration": 0.012186,
     "end_time": "2023-02-05T18:20:03.321358",
     "exception": false,
     "start_time": "2023-02-05T18:20:03.309172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "CHANNELS=3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ee1ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T18:20:03.346305Z",
     "iopub.status.busy": "2023-02-05T18:20:03.340907Z",
     "iopub.status.idle": "2023-02-05T18:20:03.936009Z",
     "shell.execute_reply": "2023-02-05T18:20:03.935326Z",
     "shell.execute_reply.started": "2023-02-05T18:17:54.343915Z"
    },
    "papermill": {
     "duration": 0.608987,
     "end_time": "2023-02-05T18:20:03.936164",
     "exception": false,
     "start_time": "2023-02-05T18:20:03.327177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monet TFRecord files: 5\n",
      "Monet image files: 300\n",
      "Photo TFRecord files: 20\n",
      "Photo image files: 7038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 18:20:03.833163: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
      "2023-02-05 18:20:03.884174: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"
     ]
    }
   ],
   "source": [
    "GCS_PATH = KaggleDatasets().get_gcs_path()\n",
    "\n",
    "MONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))\n",
    "PHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "n_monet_samples = count_data_items(MONET_FILENAMES)\n",
    "n_photo_samples = count_data_items(PHOTO_FILENAMES)\n",
    "\n",
    "print(f'Monet TFRecord files: {len(MONET_FILENAMES)}')\n",
    "print(f'Monet image files: {n_monet_samples}')\n",
    "print(f'Photo TFRecord files: {len(PHOTO_FILENAMES)}')\n",
    "print(f'Photo image files: {n_photo_samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ea630",
   "metadata": {
    "papermill": {
     "duration": 0.006133,
     "end_time": "2023-02-05T18:20:03.949485",
     "exception": false,
     "start_time": "2023-02-05T18:20:03.943352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.836836,
   "end_time": "2023-02-05T18:20:07.208950",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-05T18:19:43.372114",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
